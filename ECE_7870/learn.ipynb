{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression: Student grade prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:\\\\Users\\\\Zayan\\\\Documents\\\\datasets\\\\student+performance\\\\student\"\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_csv(f\"{file_path}\\\\student-mat.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: The file '{file_path}' is empty.\")\n",
    "\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"Error: Unable to parse the CSV file '{file_path}'. Check the file format.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>at_home</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
       "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
       "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
       "\n",
       "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0    ...      4        3      4     1     1      3        6   5   6   6  \n",
       "1    ...      5        3      3     1     1      3        4   5   5   6  \n",
       "2    ...      4        3      2     2     3      3       10   7   8  10  \n",
       "3    ...      3        2      2     1     1      5        2  15  14  15  \n",
       "4    ...      4        3      2     1     2      5        4   6  10  10  \n",
       "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
       "390  ...      5        5      4     4     5      4       11   9   9   9  \n",
       "391  ...      2        4      5     3     4      2        3  14  16  16  \n",
       "392  ...      5        5      3     3     3      3        3  10   8   7  \n",
       "393  ...      4        4      1     3     4      5        0  11  12  10  \n",
       "394  ...      3        2      3     3     3      5        5   8   9   9  \n",
       "\n",
       "[395 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_set = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "K = 10\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=K, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of training data = 60000\n",
      "number of batches = 6000\n",
      "shape of a sample =  2\n",
      "sample feature data:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
      "          0.0706, 0.0706, 0.0706, 0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.1412, 0.3686, 0.6039, 0.6667,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7765, 0.7137, 0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 0.6118, 0.4196, 0.9922, 0.9922,\n",
      "          0.8039, 0.0431, 0.0000, 0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.0039, 0.6039, 0.9922,\n",
      "          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922,\n",
      "          0.7451, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451,\n",
      "          0.9922, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373,\n",
      "          0.9451, 0.8824, 0.6275, 0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3176, 0.9412, 0.9922, 0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1765, 0.7294, 0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0627, 0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1804, 0.5098, 0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529,\n",
      "          0.5804, 0.8980, 0.9922, 0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.4471, 0.8667,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.2588, 0.8353, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.7765, 0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.7647, 0.3137, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922, 0.9922, 0.9922, 0.9569, 0.5216,\n",
      "          0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314, 0.5294, 0.5176, 0.0627, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000]]])\n",
      "sample label data:\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(\"len of training data =\", len(train_set))\n",
    "print(\"number of batches =\", len(train_loader))\n",
    "\n",
    "print(\"shape of a sample = \", len(train_set[0]))\n",
    "\n",
    "print(\"sample feature data:\")\n",
    "print(train_set[0][0]) # features\n",
    "print(\"sample label data:\")\n",
    "print(train_set[0][1]) # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zayan\\anaconda3\\envs\\ci_win\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.train_labels.bincount() # count of each label in train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study a single sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_set)) # convert train_set to an iterable and access first element\n",
    "print(len(sample)) # len of sample\n",
    "print(type(sample)) # type of sample\n",
    "\n",
    "image, label = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "          0.0706, 0.0706, 0.0706, 0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.1412, 0.3686, 0.6039, 0.6667,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7765, 0.7137, 0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 0.6118, 0.4196, 0.9922, 0.9922,\n",
       "          0.8039, 0.0431, 0.0000, 0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.0039, 0.6039, 0.9922,\n",
       "          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922,\n",
       "          0.7451, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451,\n",
       "          0.9922, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373,\n",
       "          0.9451, 0.8824, 0.6275, 0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3176, 0.9412, 0.9922, 0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.1765, 0.7294, 0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0627, 0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.1804, 0.5098, 0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529,\n",
       "          0.5804, 0.8980, 0.9922, 0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.4471, 0.8667,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.2588, 0.8353, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.7765, 0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.7647, 0.3137, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922, 0.9922, 0.9922, 0.9569, 0.5216,\n",
       "          0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314, 0.5294, 0.5176, 0.0627, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "print('label: ',label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of images:  10\n",
      "shape of images:  torch.Size([10, 1, 28, 28])\n",
      "shape of 1 image:  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "images, labels = batch\n",
    "\n",
    "print(\"len of images: \",len(images))\n",
    "print(\"shape of images: \", images.shape)\n",
    "print(\"shape of 1 image: \", images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot whole batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMEAAACqCAYAAACkqFiHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAArXElEQVR4nO3deXRUVbbH8R0wFASSAAIJMYB5GEEJgyBiEIFGiWIjID4FFQTpbmXUPBQU4WlaJUEUnigCIjI4dXQ1o90opAUCdMRFGFoE5dGIDJIYpYGEAAnDfX/04r7aJ0kllVRluPX9rJW1zi+nqu7G3Kpbdbx3V5BlWZYAAAAAAAAADlarqgsAAAAAAAAA/I1FMAAAAAAAADgei2AAAAAAAABwPBbBAAAAAAAA4HgsggEAAAAAAMDxWAQDAAAAAACA47EIBgAAAAAAAMdjEQwAAAAAAACOxyIYAAAAAAAAHI9FMAAAAAAAADie3xbB5s2bJzExMVK3bl3p0qWLbNmyxV+bAgAAAAAAADy6yh8P+sknn0hiYqLMmzdPbrvtNnnnnXekX79+sm/fPmnZsqXH+16+fFmOHz8uoaGhEhQU5I/yAAAAAAAAUENYliV5eXkSFRUltWqV/3yuIMuyLB/WJSIi3bp1k86dO8v8+fPt391www0yaNAgSUlJ8XjfY8eOSYsWLXxdEgAAAAAAAGqwo0ePSnR0dLnv7/PLIQsLC2XHjh2SkJCgfp+QkCAZGRlFbl9QUCC5ubn2jx/W5AAAAAAAAFDDhYaGVuj+Pl8E+/XXX+XSpUsSERGhfh8RESHZ2dlFbp+SkiLh4eH2T2mXSwIAAAAAACDwVLRtlt8a45uFWZZVbLFTpkyR06dP2z9Hjx71V0kAAAAAAAAIUD5vjN+kSROpXbt2kbO+cnJyipwdJiLicrnE5XL5ugwAAAAAAADA5vMzwerUqSNdunSRtLQ09fu0tDTp3r27rzcHAAAAAAAAlMrnZ4KJiEycOFGGDx8uN998s8THx8vChQvlyJEjMnr0aH9sDgAAAAAAAPDIL4tgQ4YMkRMnTshLL70kWVlZEhcXJ2vXrpVWrVr5Y3MAAAAAAACAR0GWZVlVXYS73NxcCQ8Pr+oyAAAAAAAAUI2cPn1awsLCyn1/v307JAAAAAAAAFBdsAgGAAAAAAAAx2MRDAAAAAAAAI7HIhgAAAAAAAAcj0UwAAAAAAAAOB6LYAAAAAAAAHA8FsEAAAAAAADgeCyCAQAAAAAAwPFYBAMAAAAAAIDjsQgGAAAAAAAAx2MRDAAAAAAAAI7HIhgAAAAAAAAcj0UwAAAAAAAAON5VVV0AEAi6dOmi8vjx41V+9NFHVX7//fft8VtvvaXmdu7c6ePqAAAAym7OnDkqP/nkkyp/++23Kvfv398eHz582H+FAQD87ssvv1Q5KChI5T59+lRmOV7jTDAAAAAAAAA4HotgAAAAAAAAcDwWwQAAAAAAAOB49ASrRLVr11Y5PDy8zPc1e0iFhISo3KZNG5XHjRun8uuvv67yQw89ZI/Pnz+v5mbMmKHyH//4xzLXiX/r1KmTymlpaSqHhYWpbFmWysOHD7fHAwYMUHNXX321DypEdXHHHXeo/NFHH9njXr16qbn9+/dXSk0o2bRp0+yx+dpYq5b+/0q9e/dWOT093W91AU4TGhqqcoMGDVT+7W9/q3KzZs1UnjVrlj0uKCjwcXWB59prr1V52LBhKl++fFnlG264QeW2bdvaY3qCVb3rr79e5eDgYHvcs2dPNTdv3jyVzb91RaxevVrloUOHqlxYWOizbQUK97+liEj37t1VTk5OVvm2227ze02o+f7nf/5HZXO/cu9nXRNwJhgAAAAAAAAcj0UwAAAAAAAAOB6LYAAAAAAAAHA8eoJ5qWXLlva4Tp06as68NrZHjx4qN2zYUOX777/fZ3UdO3ZM5TfffFPl++67T+W8vDx7/I9//EPN0bfGe7fccovKy5cvV9ns/2b2AHP/e4joHghmD7D4+HiVd+zYUeJ9axKzB4X57165cmVlllNpunbtqnJmZmYVVYLijBw5UuXnnnvOHpfWF8V8ngP4fzExMSpPnjxZZfNYFxcX59XjR0ZG2uMnn3zSy+pg+uWXX1TevHmzymb/UlStdu3aqWweyx544AGV3XtaRkVFqTnzWOfLY5u53yxYsEDlxMRElXNzc322bacyP3Ns3LhR5ezsbJXdXyuLm0dgMnuEjx49WuULFy6o/OWXX/q9Jl/iTDAAAAAAAAA4HotgAAAAAAAAcDwWwQAAAAAAAOB49AQrxU033aSy+/Wu5jXXlcm8Pn/atGkq5+fnq/zxxx+rfPz4cXt88uRJNbd//35flOg4ISEh9rhz585q7sMPP1S5efPmXj32gQMHVJ45c6Y9Tk1NVXNbt25V+b//+79VTk5O9mrb1UXv3r1Vjo2NVdkpPcHc+26IFO2L4953MCgoqFJqQslatWqlssvlqqJKAlO3bt1UHj58uMpmL0GzD467Z555RmX346CIyO23367yBx98oPLXX3/tuVgU0bZtW5Xd+/sMGzZMzdWtW1dl8/Xv6NGjKpu9NG+44QaVH3zwQXs8b948Nff99997qBrFMd9XHj58uIoqQVmkpKSofM8991RRJd559NFHVX7vvfdU/vvf/16Z5TiS2QOMnmAozq233qpycHCwyubn0U8//dTvNfkSZ4IBAAAAAADA8bxeBNu8ebPce++9EhUVJUFBQbJq1So1b1mWJCUlSVRUlNSrV0969+4te/fu9VW9AAAAAAAAgNe8XgTLz8+Xjh07yty5c4udnzlzpsyePVvmzp0r27dvl8jISOnbt2+R09YBAAAAAACAyuJ1T7B+/fpJv379ip2zLEveeOMNmTp1qgwePFhERJYtWyYRERHy8ccfyxNPPFGxaquA2fPgxIkT9tjXPcHc+42cOnVKzf3mN79RubCwUGWzdwl875133rHHDz30kE8f2+wx1qBBA3ucnp6u5szeWe3bt/dpLVXF7APx1VdfVVEl/mX2i/vDH/6gsnt/OfrWVL4777xT5QkTJpR4W/Pv079/f5V//vln3xUWIIYMGaLynDlzVG7SpInKZt+oTZs22eOmTZuquddee83jts3HMrc1dOhQj/cPROb7oFdffVVl8+8ZGhpa5sc2e2XeddddKtepU0fl7777TmX3v5/5t4T3GjZsqHLHjh2rphCUSVpamsql9QTLycmxx4sXL1Zz5mujZVkeHys+Pl7lXr16ebw9Khf9ZmsWs/fp1KlT7bH5efRf//pXhbbl/nhxcXFq7uDBgyqbfVZrGp/2BDt06JBkZ2dLQkKC/TuXyyW9evWSjIwMX24KAAAAAAAAKDOffjvklW+TiIiIUL+PiIgo8VtkCgoKpKCgwM65ubm+LAkAAAAAAADwz7dDFnfabEmnXqakpEh4eLj906JFC3+UBAAAAAAAgADm0zPBIiMjReTfZ4S5973JyckpcnbYFVOmTJGJEyfaOTc3t1othJnX1k6aNMkem/1fdu3apfKbb77p8bF3796tct++fe1xfn6+mmvXrp3KTz31lMfHRsV16dJF5d/+9rf2uLTr6c0+Xn/5y19UNnvTZGVlqey+L508eVLN9enTR2WnXNtfq5Zf1uSrnUWLFnmcN/vgwL969Oih8tKlS1X21PvRfB6XdMYz/t9VV+m3HV27dlX53XffVTkkJETlzZs3q/zyyy+rvHXrVnvscrnU3Keffqqye+uG4mRmZnqch8h9992n8u9///tyP5bZb8T9PZGIyNGjR1WOjY0t97bgPfO52LJlS6/u7/5cN/sp8trpe/Pnz1d51apVHm9/4cIFe3zlyp7yCgsLU/nbb79VOSoqqsT7mnXyOux7Zk+3evXqVVElKIuFCxeq7H7su/HGG9Wc+3ug8nDvN3b11VerObOH8T/+8Y8Kbauq+fRTZ0xMjERGRqpmjIWFhZKeni7du3cv9j4ul0vCwsLUDwAAAAAAAOBLXp8JdubMGfnnP/9p50OHDsnu3bulcePG0rJlS0lMTJTk5GSJjY2V2NhYSU5OlpCQEHn44Yd9WjgAAAAAAABQVl4vgmVmZspvfvMbO1+5lHHEiBGydOlSmTx5spw7d07Gjh0rJ0+elG7dusn69eu9+lrs6sz9NN0NGzaouby8PJXNr4/+3e9+p/KsWbNUNi+BdLd3716VH3/88VJrhXc6deqksvn10u5nKZqnEn/++ecqm19Za3499LRp01Q2L5H75Zdf7LF5uunly5dVdr9MU0Skc+fOKu/cuVOqow4dOqhc0iXTTuPp8jqRovsd/GvEiBEqu1/KX5xNmzbZ4/fff98fJTnasGHDVC7t8mDz+TBkyBCVPX2Zjnnb0i5/PHbsmMrLli3zeHuIPPDAA17d/scff7TH27dvV3PPPvusyublj6a2bdt6tW1UzPHjx1U2Lx1PSkryeH/3+VOnTqm5uXPnVqAyFOfixYsql/Z88qW77rpL5UaNGpX5vubrsPuXp8E/zPYvX331VRVVguKcPXtWZffPoHXr1q3QY5uffd0vczc/b1Z0W9WN14tgvXv3LrIA4C4oKEiSkpJKPRgCAAAAAAAAlSUwOlEDAAAAAAAgoLEIBgAAAAAAAMfz+nJI/D9PvUhERE6fPu1x3vwq8dTUVHtsXocL37v++utVnjRpkspm76Zff/3VHmdlZak5s3fMmTNnVP7rX//qMVeE+dXGTz/9tMqPPPKIz7blS/fcc4/KTv2KZrPXWUxMjMfb//TTT/4sJ+A1adJE5VGjRqlsvvaavWumT5/ul7qc7JVXXrHHU6ZMUXNme4V58+apbPZPLO246879q77L4sknn1TZvTcjimd+ZbrZr3T9+vUqu3+xUk5OToW2HSh9JKurl19+WWXaoASuoUOHqmy+Lnjz/u6FF17wSU2BzOwHZ34eNT/ftG7d2u81oezM19b27dur/P3339tjs290aerXr6+y2YszJCTEHm/btk3N/fnPf/ZqW9UdZ4IBAAAAAADA8VgEAwAAAAAAgOOxCAYAAAAAAADHoyeYH5n9Ebp06aJyr169VL7zzjvtsdlHAxXncrlUfv3111U2e1Tl5eWp/Oijj9rjzMxMNVed+lm1bNmyqksokzZt2nic37t3byVV4l/mfmb2sfnf//1flc39DhVz7bXXqrx8+XKv7v/WW2+pvGHDhoqW5HhmTxf3PmCFhYVqbt26dSqb/SnOnTvncVt169ZVOSEhwR6br4VBQUEqu/cqExFZvXq1x22hqOPHj6tcmX2h4uPjK21bKF2tWvr/q9Pb1jnM3rJmb0ezp1RwcHCZH3v37t0qX7hwwbviUITZy3TLli0q9+/fvxKrQWlatGihstlTz+zxNm7cOHvsbe/S2bNnq/zAAw+o7H5Mv+2227x67JqGM8EAAAAAAADgeCyCAQAAAAAAwPFYBAMAAAAAAIDj0RPMj/Lz81U2r/HduXOnyu+++6493rhxo5oze1C9/fbbKluWVe46A0Xnzp1VNnuAmQYOHKhyenq6z2tCybZv317VJZQoLCzMHt99991qbtiwYSq79ygqzssvv6yy2csBFWP+fTp06ODx9l9++aXKc+bM8XlNTtOwYUOVx44dq7L78cnsATZo0CCvtnXdddep/NFHH6ls9t509+c//1nlmTNnerVt+NaTTz6pcv369VU2e7iZ73Pat2/v8fEzMjLs8VdffVWeEuEFswcY70urltkPc/jw4Sq79yEuTY8ePVT29m+bm5ur8nPPPWeP165dq+ZK6wMJ1HTmsWvFihUqN2nSRGWzN603n0efeeYZlUeOHOnx9tOnTy/zY9d0nAkGAAAAAAAAx2MRDAAAAAAAAI7HIhgAAAAAAAAcj55glejgwYMqm9flLlmyxB6b1+6b2eyd8f7776uclZVV3jIda9asWSqb/UbMa6yraw+wWrX02rXZh8P8d9VUjRs3Lvd9O3bsqLL53+yOO+5QOTo6WuU6deqo/Mgjj5T4eGb/iq+//lrlgoICla+6Sr/s7tixQ+A7Zo+pGTNmeLz91q1bVR4xYoTKp0+f9kldTmY+X8x+Fu7MPlDNmjVT+bHHHlN5wIABKsfFxancoEEDld171Zh9az788EOVzb6dqLiQkBCV27Vrp/ILL7xgj0vry1nasc5kvu9x35cuXbrk8b5ATWf2GVq9erXKLVu2rMxylC1btqi8cOHCKqoExbn66qurugRHMd/nm72C33vvPZVLO9bFx8er/Pzzz9tj87Ot+dnpgQceUNn8jGiuH7zzzjsSKDgTDAAAAAAAAI7HIhgAAAAAAAAcj0UwAAAAAAAAOB49warQypUrVf7nP/9pj81rfM0eRsnJySq3atVK5enTp6v8008/lbvOmqp///4qd+rUSWWzX8yaNWv8XZJPmNeKm/+O3bt3V2I15Wf20jL/HQsWLFDZ/Rr40nTo0EFl8xr4ixcvqnz27FmV9+3bp/LixYtVzszMtMdm77iff/5Z5WPHjqlcr149lb///ntBxVx77bX2ePny5V7d94cfflDZ/PuhdIWFhSr/8ssvKjdt2tQeHzp0SM2Zz/vSHD9+XOXc3FyVmzdvbo9//fVXNffZZ595tS0UFRwcrPJNN92ksvn8c/97iOjXfbOHV0ZGhsp33323yma/MVPt2rVVHjx4sD2eM2eOmjP3WcBpzPc9FekX621/PpP5fty9H+DatWvLXRd8w+y9iYoZOnSoyosWLVLZfN9jPp/c1wNERG6++eYSs/m3u+aaa1Q2j8Hm+7NRo0ZJoOJMMAAAAAAAADgei2AAAAAAAABwPBbBAAAAAAAA4Hj0BKtG9uzZY48ffPBBNXfvvfeqvGTJEpWfeOIJlWNjY1Xu27evL0qsUczeS3Xq1FE5JydH5U8++cTvNZWVy+Wyx0lJSR5vu2HDBpWfe+45f5Tkc2PHjlX58OHDKnfv3r3cj33kyBGVV69erbLZ82vbtm3l3pbp8ccfV9m9H5JI0R5UqLhnn33WHnvbq2TGjBm+LifgnDp1SuVBgwap/Je//MUeN27cWM0dPHhQZfO5unTpUpX/9a9/qZyamqqye/8Lcw7eM4+bZp+uFStWeLz/H//4R5Xdj1d///vf1Zy5b5jHtri4OI/bMl9rU1JS7LF5TFi1apXKBQUFHh8bpfOmb1TPnj1Vnjt3rl9qCiTunyFERHr37q3ysGHDVF63bp3K58+fL/e2f/e736k8YcKEcj8WfG/jxo0qmz3aUHFDhgyxx+Zn9AsXLqhsvmd6+OGHVT558qTKZp/wXr162WOzX5jZ+8/sP9akSROVjx49qrL764b5/sxpOBMMAAAAAAAAjsciGAAAAAAAAByPRTAAAAAAAAA4Hj3BqinzeuEPPvhA5UWLFql81VX6T2n2WzB7A2zatKlC9TmB2QMkKyuriirRPcBERKZNm2aPJ02apOaOHTumsnmt+JkzZ3xcXeV49dVXq7oEn7jjjjs8zi9fvrySKnGuTp06qZyQkFDm+5o9p/bv3++LkuDm66+/Vtns1VQR5rHNvTeGiO5DRP897wUHB6ts9vQyj0emL774QuW33npLZff3NuZ+sXbtWpXbt2+vcmFhocozZ85U2ewZNnDgQHv80Ucfqbm//e1vHh/L7Mli2rVrl8f5QGT2ADN70bgbPHiwyjfeeKPKZt9OeM/sszp9+nS/bcvsXUtPsOrF7IloMl/3W7VqZY/N/QjFc+/Nbf73Np97ixcv9uqxzefTwoUL7fGtt97q1WOZPcPMfnFO7wPmjjPBAAAAAAAA4HheLYKlpKRI165dJTQ0VJo1ayaDBg0q8n/RLcuSpKQkiYqKknr16knv3r1l7969Pi0aAAAAAAAA8IZXl0Omp6fLuHHjpGvXrnLx4kWZOnWqJCQkyL59+6R+/foi8u9TymfPni1Lly6V66+/Xl555RXp27ev7N+/X0JDQ/3yj3CKDh062OP//M//VHNdu3ZV2bz80WSeSr558+YKVuc8a9asqbJtm5dzmZeYuH/Vrnn51v333++3uuB/q1atquoSarz169er3KhRoxJva16aN3LkSH+UhEpSr149lT1dgpWamlopNdV0tWvXtscvv/yymnvmmWdUzs/PV3nKlCkq/+lPf1LZbO3g/l7GvFTypptuUvnAgQMqjxkzRmXzMo6wsDCVu3fvbo8feeQRNTdgwACVzdcUk/k18jExMR5vH4gWLFigsvvlQaV5/PHHVU5MTPRFSagkd911V1WXAA8uXrzocd68RM5s0YLSuX9WW7FihZozjx/eatKkicrt2rUr8bYPPfSQyt9++63HxzZb7AQSrxbBzF4PS5YskWbNmsmOHTukZ8+eYlmWvPHGGzJ16lT7ev9ly5ZJRESEfPzxx14dEAEAAAAAAABfqVBPsNOnT4uISOPGjUVE5NChQ5Kdna2aFLtcLunVq5dkZGQU+xgFBQWSm5urfgAAAAAAAABfKvcimGVZMnHiROnRo4f9jTzZ2dkiIhIREaFuGxERYc+ZUlJSJDw83P5p0aJFeUsCAAAAAAAAiuXV5ZDuxo8fL998841s3bq1yJx5bbFlWUV+d8WUKVNk4sSJds7NzXXsQlibNm1UNr/y9L777rPHkZGRXj32pUuXVM7KylLZ7JsSCMx9zsyDBg1S+amnnvJbLe77uIjItGnTVA4PD1fZ/evcH330Ub/VBdREV199tcqeXt/efvttlc+cOeOXmlA51q1bV9UlOI57PyazB9jZs2dVNttamL20zK9rf+yxx1S+55577HHdunXV3EsvvaTykiVLVC6tr4p5JYF7Cw+znYfZN8XsGWb6r//6L4/zEPn++++rugTHCw4OtsfuV92IiGzYsEHlc+fO+a2OUaNGqfzGG2/4bVuoOLO3sPlcbdu2rcruPfnGjh3rt7qcZM6cOT57LPMz4YMPPqiye//LgwcPqrlPP/3UZ3U4XbkWwSZMmCBr1qyRzZs3S3R0tP37Kws32dnZ0rx5c/v3OTk5Rc4Ou8LlctGADwAAAAAAAH7l1eWQlmXJ+PHjZcWKFbJhw4Yi344TExMjkZGRkpaWZv+usLBQ0tPT1bf0AAAAAAAAAJXJqzPBxo0bJx9//LGsXr1aQkND7T5f4eHhUq9ePQkKCpLExERJTk6W2NhYiY2NleTkZAkJCZGHH37YL/8AAAAAAAAAoDReLYLNnz9fRER69+6tfr9kyRIZOXKkiIhMnjxZzp07J2PHjpWTJ09Kt27dZP369RIaGuqTgqszs4+XufA3btw4la+99tpybyszM1Pl6dOnq7xmzZpyP7ZTWJblMZt/rzfffFPlxYsXq3zixAl7bPY9GT58uModO3ZU2f2yYRGRI0eOqGz2uZk3b57AGcxedLGxsSp/9dVXlVlOjWT2BqpVq+wnMZf0zcSome66666qLsFxXnjhhRLnateurfKkSZNUTkpKUvm6664r83bN+6akpKhs9jr1pT/96U8eM7z31ltvqWz2vW3dunWJ9zV7spqPZfa9CRS33367ys8//7w97tu3r5ozr84prYeeJ40bN1bZvZefiMisWbNUDgkJ8fh4Zn8yf/YrQ+nMXo7XXHONymYfY1Qusw/b6NGjVc7JybHHffr0qZSanMirRTBzEaE4QUFBkpSUVOTNDQAAAAAAAFBVvOoJBgAAAAAAANRELIIBAAAAAADA8by6HBIiERER9rhdu3Zqzuxh0LZt23Jv5+uvv1b5tddeU3n16tUqX758udzbClRmrxPzGuz7779f5dzcXHts9nUqjdn3acOGDSp76smCms28jNybflaBqlOnTiqbvU/M17vCwkJ7/Pbbb6u5n3/+2bfFoUp56iuE8rnyJUciIk2bNlVzLpdLZbPfpWnt2rUqb968WeVVq1bZ4x9//FHN+bMHGCrf3r17Vf6P//iPEm/Le9jimZ8r4uLiSrzt5MmTVc7Lyyv3ds1jbufOnVUurT3Opk2bVL7SU/qKjRs3lrs2+J7593R/TwX/a9Wqlcq///3vVTb/PgsXLrTHx44d819hDsenMQAAAAAAADgei2AAAAAAAABwPBbBAAAAAAAA4Hj0BDM0btxY5XfeeUdl9141nvoblEVGRobKs2bNssfr1q1Tc+fOnavQtgKR2Ydr+/btKnft2tXj/SMjI1V27wdnOnHihMqpqakqP/XUUx63hcARHx+v8tKlS6umkGqsYcOGKnt67omI/PTTT/b4mWee8UdJqCa2bNmistljj95C3uvZs6c9HjRokJozewHl5OSovHjxYpVPnjypMr1lApd73xoRkXvvvbeKKgkMY8aMqbRtma8Dn332mcrme97z58/7vSaUX1hYmMrux4EVK1ZUcjWBJy0tTWWzR9iHH36o8osvvuj3mgIBZ4IBAAAAAADA8VgEAwAAAAAAgOOxCAYAAAAAAADHC7ieYN26dVN50qRJKt9yyy0qX3PNNeXeltnHa86cOSonJyernJ+fX+5toahjx46pPHjwYJWfeOIJladNm1bmxzb/lgsWLFD5wIEDZX4sOFtQUFBVlwA4xp49e1Q2X2vde3W2bt1azf3yyy/+K6wGy8vLs8cffPCBmjMzUFb79u1T+bvvvrPHN9xwQ2WXUyM99thjKo8fP94ejxgxwqfbOnjwoD0+e/asmjN7Mb777rsqm6/LqN4efPBBlQsKClQ2n7vwL7M38EsvvaTymjVrKrGawMGZYAAAAAAAAHA8FsEAAAAAAADgeCyCAQAAAAAAwPGCLMuyqroId7m5uRIeHu63x58xY4bKZk+w0rj3NPjss8/U3KVLl1R+/fXXVT516pRX2wJQ84wcOVLlxYsXq2z20jB700EkMjJS5U8++UTlHj16qHzo0CF7fN111/mvMFQ75vNt0aJF9jg9PV3NTZgwQWX6ngCoSVwulz02X/teeeUVlRs1aqTyqlWrVE5LS1N59erV9jg7O7sCVaK6S01NVdns0TdgwAB7fPjw4UqpCfDW6dOnJSwsrNz350wwAAAAAAAAOB6LYAAAAAAAAHA8FsEAAAAAAADgeAHXEwwAADiD2Q/i008/tcd33nmnmluxYoXKjz32mMr5+fk+rg4AAAC+Rk8wAAAAAAAAoBQsggEAAAAAAMDxuBwSAAA4gvup8dOnT1dzY8aMUblDhw4q79u3z3+FAQAAwCe4HBIAAAAAAAAoBYtgAAAAAAAAcDwWwQAAAAAAAOB49AQDAAAAAABAtUdPMAAAAAAAAKAUXi2CzZ8/Xzp06CBhYWESFhYm8fHx8vnnn9vzlmVJUlKSREVFSb169aR3796yd+9enxcNAAAAAAAAeMOrRbDo6GiZMWOGZGZmSmZmpvTp00cGDhxoL3TNnDlTZs+eLXPnzpXt27dLZGSk9O3bV/Ly8vxSPAAAAAAAAFAWFe4J1rhxY3nttddk1KhREhUVJYmJifLss8+KiEhBQYFERETIq6++Kk888USZHo+eYAAAAAAAADBVWU+wS5cuSWpqquTn50t8fLwcOnRIsrOzJSEhwb6Ny+WSXr16SUZGRrkLBAAAAAAAACrqKm/vsGfPHomPj5fz589LgwYNZOXKlXLjjTfaC10RERHq9hEREXL48OESH6+goEAKCgrsnJub621JAAAAAAAAgEdenwnWpk0b2b17t2zbtk3GjBkjI0aMkH379tnzQUFB6vaWZRX5nbuUlBQJDw+3f1q0aOFtSQAAAAAAAIBHFe4Jduedd0rr1q3l2WefldatW8vOnTvlpptusucHDhwoDRs2lGXLlhV7/+LOBGMhDAAAAAAAAO6qrCfYFZZlSUFBgcTExEhkZKSkpaXZc4WFhZKeni7du3cv8f4ul0vCwsLUDwAAAAAAAOBLXvUEe/7556Vfv37SokULycvLk9TUVNm0aZN88cUXEhQUJImJiZKcnCyxsbESGxsrycnJEhISIg8//LC/6gcAAAAAAABK5dUi2M8//yzDhw+XrKwsCQ8Plw4dOsgXX3whffv2FRGRyZMny7lz52Ts2LFy8uRJ6datm6xfv15CQ0PLvI0KXp0JAAAAAAAAB6romlGFe4L52rFjx+gJBgAAAAAAAOXo0aMSHR1d7vtXu0Wwy5cvy/Hjx8WyLGnZsqUcPXqUPmEISFe+JILnAAIR+z8CHc8BBDL2fwQ6ngMIZCXt/5ZlSV5enkRFRUmtWuVvb+/V5ZCVoVatWhIdHS25ubkiIjTLR8DjOYBAxv6PQMdzAIGM/R+BjucAAllx+394eHiFH7fC3w4JAAAAAAAAVHcsggEAAAAAAMDxqu0imMvlkhdffFFcLldVlwJUCZ4DCGTs/wh0PAcQyNj/Eeh4DiCQ+Xv/r3aN8QEAAAAAAABfq7ZnggEAAAAAAAC+wiIYAAAAAAAAHI9FMAAAAAAAADgei2AAAAAAAABwvGq7CDZv3jyJiYmRunXrSpcuXWTLli1VXRLgc0lJSRIUFKR+IiMj7XnLsiQpKUmioqKkXr160rt3b9m7d28VVgxUzObNm+Xee++VqKgoCQoKklWrVqn5suzzBQUFMmHCBGnSpInUr19fBgwYIMeOHavEfwVQPqXt/yNHjixyTLj11lvVbdj/UVOlpKRI165dJTQ0VJo1ayaDBg2S/fv3q9twDIBTlWX/5xgAJ5s/f7506NBBwsLCJCwsTOLj4+Xzzz+35yvz9b9aLoJ98sknkpiYKFOnTpVdu3bJ7bffLv369ZMjR45UdWmAz7Vr106ysrLsnz179thzM2fOlNmzZ8vcuXNl+/btEhkZKX379pW8vLwqrBgov/z8fOnYsaPMnTu32Pmy7POJiYmycuVKSU1Nla1bt8qZM2ekf//+cunSpcr6ZwDlUtr+LyJy9913q2PC2rVr1Tz7P2qq9PR0GTdunGzbtk3S0tLk4sWLkpCQIPn5+fZtOAbAqcqy/4twDIBzRUdHy4wZMyQzM1MyMzOlT58+MnDgQHuhq1Jf/61q6JZbbrFGjx6tfte2bVvrueeeq6KKAP948cUXrY4dOxY7d/nyZSsyMtKaMWOG/bvz589b4eHh1oIFCyqpQsB/RMRauXKlncuyz586dcoKDg62UlNT7dv89NNPVq1atawvvvii0moHKsrc/y3LskaMGGENHDiwxPuw/8NJcnJyLBGx0tPTLcviGIDAYu7/lsUxAIGnUaNG1qJFiyr99b/anQlWWFgoO3bskISEBPX7hIQEycjIqKKqAP85cOCAREVFSUxMjAwdOlR++OEHERE5dOiQZGdnq+eCy+WSXr168VyAI5Vln9+xY4dcuHBB3SYqKkri4uJ4XsARNm3aJM2aNZPrr79e/vCHP0hOTo49x/4PJzl9+rSIiDRu3FhEOAYgsJj7/xUcAxAILl26JKmpqZKfny/x8fGV/vpf7RbBfv31V7l06ZJERESo30dEREh2dnYVVQX4R7du3eT999+XdevWybvvvivZ2dnSvXt3OXHihL2/81xAoCjLPp+dnS116tSRRo0alXgboKbq16+ffPTRR7JhwwaZNWuWbN++Xfr06SMFBQUiwv4P57AsSyZOnCg9evSQuLg4EeEYgMBR3P4vwjEAzrdnzx5p0KCBuFwuGT16tKxcuVJuvPHGSn/9v6oC/wa/CgoKUtmyrCK/A2q6fv362eP27dtLfHy8tG7dWpYtW2Y3wuS5gEBTnn2e5wWcYMiQIfY4Li5Obr75ZmnVqpX89a9/lcGDB5d4P/Z/1DTjx4+Xb775RrZu3VpkjmMAnK6k/Z9jAJyuTZs2snv3bjl16pQsX75cRowYIenp6fZ8Zb3+V7szwZo0aSK1a9cuspqXk5NTZGUQcJr69etL+/bt5cCBA/a3RPJcQKAoyz4fGRkphYWFcvLkyRJvAzhF8+bNpVWrVnLgwAERYf+HM0yYMEHWrFkjGzdulOjoaPv3HAMQCEra/4vDMQBOU6dOHbnuuuvk5ptvlpSUFOnYsaPMmTOn0l//q90iWJ06daRLly6Slpamfp+Wlibdu3evoqqAylFQUCDfffedNG/eXGJiYiQyMlI9FwoLCyU9PZ3nAhypLPt8ly5dJDg4WN0mKytLvv32W54XcJwTJ07I0aNHpXnz5iLC/o+azbIsGT9+vKxYsUI2bNggMTExap5jAJystP2/OBwD4HSWZUlBQUHlv/6Xs5G/X6WmplrBwcHWe++9Z+3bt89KTEy06tevb/34449VXRrgU08//bS1adMm64cffrC2bdtm9e/f3woNDbX39RkzZljh4eHWihUrrD179lgPPfSQ1bx5cys3N7eKKwfKJy8vz9q1a5e1a9cuS0Ss2bNnW7t27bIOHz5sWVbZ9vnRo0db0dHR1t/+9jdr586dVp8+fayOHTtaFy9erKp/FlAmnvb/vLw86+mnn7YyMjKsQ4cOWRs3brTi4+Ota665hv0fjjBmzBgrPDzc2rRpk5WVlWX/nD171r4NxwA4VWn7P8cAON2UKVOszZs3W4cOHbK++eYb6/nnn7dq1aplrV+/3rKsyn39r5aLYJZlWW+//bbVqlUrq06dOlbnzp3V18cCTjFkyBCrefPmVnBwsBUVFWUNHjzY2rt3rz1/+fJl68UXX7QiIyMtl8tl9ezZ09qzZ08VVgxUzMaNGy0RKfIzYsQIy7LKts+fO3fOGj9+vNW4cWOrXr16Vv/+/a0jR45Uwb8G8I6n/f/s2bNWQkKC1bRpUys4ONhq2bKlNWLEiCL7Nvs/aqri9n0RsZYsWWLfhmMAnKq0/Z9jAJxu1KhR9vpO06ZNrTvuuMNeALOsyn39D7Isy/Lu3DEAAAAAAACgZql2PcEAAAAAAAAAX2MRDAAAAAAAAI7HIhgAAAAAAAAcj0UwAAAAAAAAOB6LYAAAAAAAAHA8FsEAAAAAAADgeCyCAQAAAAAAwPFYBAMAAAAAAIDjsQgGAAAAAAAAx2MRDAAAAAAAAI7HIhgAAAAAAAAcj0UwAAAAAAAAON7/ARO8rvvWp+lLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = torchvision.utils.make_grid(images, nrow=10)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "\n",
    "print('labels', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(VanillaNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) # 1 input color channel x 6 filters = 6 response fields\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5) # 6 input response fields x 12 filters = 72 response fields (12 for each input field)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) # Why in_channels=12*4*4?\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.layer(t)\n",
    "        return t\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaNetwork(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([12, 6, 5, 5])\n",
      "torch.Size([120, 192])\n",
      "torch.Size([60, 120])\n",
      "torch.Size([10, 60])\n"
     ]
    }
   ],
   "source": [
    "net = VanillaNetwork()\n",
    "print(net)\n",
    "\n",
    "# conv layer weight shape = [# filters, # depth of filters = # input, # of height, # width]\n",
    "# dense layer weight shape = [# output features, # input features]\n",
    "print(net.conv1.weight.shape)\n",
    "print(net.conv2.weight.shape)\n",
    "print(net.fc1.weight.shape)\n",
    "print(net.fc2.weight.shape)\n",
    "print(net.out.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0847, -0.1357, -0.1344, -0.0212,  0.1297],\n",
       "          [ 0.0996, -0.1883, -0.0733,  0.0814, -0.1574],\n",
       "          [-0.1511,  0.1390, -0.0871,  0.1403, -0.0229],\n",
       "          [ 0.1405, -0.1275,  0.1056, -0.1269,  0.0449],\n",
       "          [ 0.1016,  0.0825, -0.1321,  0.1055, -0.1386]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0615,  0.1697, -0.1180, -0.0754, -0.1885],\n",
       "          [ 0.1604, -0.1520,  0.1810, -0.1485,  0.1285],\n",
       "          [-0.0352, -0.0291, -0.0389, -0.0540,  0.1457],\n",
       "          [-0.0112,  0.0902,  0.0376, -0.0534, -0.0929],\n",
       "          [ 0.0267,  0.0977,  0.1986,  0.1222, -0.1570]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0883, -0.1381,  0.1843,  0.1773,  0.1930],\n",
       "          [-0.1396,  0.1731, -0.1045, -0.0976,  0.0807],\n",
       "          [-0.0633,  0.1308, -0.0836,  0.1971, -0.0303],\n",
       "          [-0.0993,  0.1341,  0.1685,  0.0762,  0.1217],\n",
       "          [-0.1918, -0.1582,  0.0741,  0.0290,  0.0483]]],\n",
       "\n",
       "\n",
       "        [[[-0.1541, -0.1136,  0.1958, -0.0742,  0.0154],\n",
       "          [-0.0977, -0.0111,  0.0295, -0.1759,  0.0195],\n",
       "          [ 0.1639, -0.0815, -0.0465,  0.0299, -0.1416],\n",
       "          [ 0.1853,  0.1029, -0.0576, -0.1602, -0.0291],\n",
       "          [ 0.1980, -0.1963,  0.1680,  0.1745, -0.0322]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0928, -0.1700,  0.0034, -0.0222,  0.0493],\n",
       "          [-0.0182, -0.1117,  0.1549, -0.1680, -0.1638],\n",
       "          [-0.0047,  0.0554, -0.1718, -0.1908, -0.0434],\n",
       "          [-0.1172, -0.0584, -0.0356,  0.0946,  0.1152],\n",
       "          [-0.1539, -0.1581, -0.1881, -0.1500,  0.1549]]],\n",
       "\n",
       "\n",
       "        [[[-0.0778, -0.0646,  0.0126,  0.0496, -0.0180],\n",
       "          [-0.0516, -0.0060,  0.0927, -0.1907, -0.0007],\n",
       "          [-0.0005,  0.0592, -0.0538, -0.1847,  0.0072],\n",
       "          [-0.0839, -0.1211, -0.0962,  0.0186, -0.1702],\n",
       "          [-0.0275,  0.0050,  0.1391, -0.1423,  0.1366]]]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([30, 40, 50])\n"
     ]
    }
   ],
   "source": [
    "in_features = torch.tensor([1,2,3,4])\n",
    "weights = torch.tensor([[1,2,3,4],\n",
    "                        [2,3,4,5],\n",
    "                        [3,4,5,6]])\n",
    "\n",
    "out_features = weights @ in_features\n",
    "print(out_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Access all parameters in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([12, 6, 5, 5])\n",
      "torch.Size([12])\n",
      "torch.Size([120, 192])\n",
      "torch.Size([120])\n",
      "torch.Size([60, 120])\n",
      "torch.Size([60])\n",
      "torch.Size([10, 60])\n",
      "torch.Size([10])\n",
      "\n",
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.shape)\n",
    "    \n",
    "print()\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dr Anderson's CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets name oue neural network \"CNN_Anderson\"\n",
    "class CNN_Anderson(nn.Module):\n",
    "    \n",
    "    # this is our CNN_Anderson initilization function     \n",
    "    def __init__(self, size, num_classes):\n",
    "        # self is ... well ourself! (https://www.askpython.com/python/python-self-variable)\n",
    "        # other variables are ones we made up\n",
    "        #   size is the number of spectral bands in our image (e.g., MNIST is 1, RGB imagery is 3)\n",
    "        #   num_classes is the number of output neurons (e.g., num_classes = 10 for 10 classes in MNIST)\n",
    "\n",
    "        # lets call our super function (https://www.pythonforbeginners.com/super/working-python-super-function)\n",
    "        # we do this first,  call its init fx\n",
    "        super(CNN_Anderson, self).__init__()\n",
    "\n",
    "        # here is our \"feature extraction\" via convolutional layers \n",
    "        #   note: assume we got a single channel (grayscale) MNIST image of size 28x28x1\n",
    "        #         first layer\n",
    "        #             28x28x1 -> convolution (1 stride, 1 padd, 3x3 kernel, 2 kernels) -> 28x28x2\n",
    "        #         pooling\n",
    "        #             pool of 2x2 => 28x28 / 2 => 14x14 now (technically, 14x14x2 right!)\n",
    "        #         second layer\n",
    "        #             14x14x2 -> convolution (1 stride, 1 padd, 3x3 kernel, 4 kernels) -> 14x14x4\n",
    "        #         pooling\n",
    "        #             pool of 2x2 => 14x14 / 2 => 7x7 now (technically, 7x7x4 right!)\n",
    "        self.extract = nn.Sequential( # lets make a 2D convolution layer\n",
    "                                      nn.Conv2d( in_channels = size, out_channels = 2, \n",
    "                                                 kernel_size = 3, stride = 1, padding = 1), \n",
    "                                                     # in_channels = 1 for MNIST and 3 for RGB image\n",
    "                                                     # out_channels = 2 means 2 shared weights/features\n",
    "                                                     # kernel_size = 3 means a 3x3 size kernel\n",
    "                                                     # stride = 1 means move one pixel at a time in each dim\n",
    "                                                     # padding = adds one pixel of zeros to each side of each dim\n",
    "                                                     #           note, thats what keeps our spatial dims the same for a 3x3 kernel\n",
    "                                                     #           it also lets us process each location, even that border!!!\n",
    "                                      # its a NN, lets run a non-linearity on each of those results!\n",
    "                                      nn.ReLU(inplace = True),\n",
    "                                                     # could also use torch.nn.Sigmoid or etc.\n",
    "                                                     # inplace means don't have to return a result, do it on the data\n",
    "                                      # ----------------------------------------------------------- \n",
    "                                      # !!! hey, we just made a layer of convolution/nonlin !!!\n",
    "                                      # ----------------------------------------------------------- \n",
    "                                      # lets pool using a 2x2 region that is not overlapping\n",
    "                                      nn.MaxPool2d(2),                                                  \n",
    "                                      # lets do dropout with a small percentage/rate               \n",
    "                                      # nn.Dropout(0.1),\n",
    "                                      # ----------------------------------------------------------- \n",
    "                                      # now, lets make another layer of convolution, pooling, and drop out\n",
    "                                      nn.Conv2d( in_channels = 2, out_channels = 4, \n",
    "                                                 kernel_size = 3, stride = 1, padding = 1),\n",
    "                                                 # in_channels here needs to match out_channels above\n",
    "                                                 # lets use 5 filters \n",
    "                                      nn.ReLU(inplace = True),\n",
    "                                      nn.MaxPool2d(2),\n",
    "                                      nn.Dropout(0.1), )\n",
    "\n",
    "        # ok, now we are going to make a simple MLP classifier on the end of our above features\n",
    "        self.decimate = nn.Sequential( nn.Linear(4*(7*7), 12),  \n",
    "                                            # take our 4 filters whose response fields are 7x7 to 12 neurons\n",
    "                                       nn.ReLU(inplace = True), # run a nonlinearity\n",
    "                                       nn.Dropout(0.2), # some drop out\n",
    "                                       nn.Linear(12, num_classes) ) # map the 32 down to our number of output classes\n",
    " \n",
    "    #----------------------------\n",
    "    # Model: Invoke Forward Pass\n",
    "    #----------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        features = self.extract(x) # easy, pass input (x) to our \"feature extraction\" above\n",
    "        features = features.view(features.size()[0], -1) # now, flatten 7x7x4 matrix to 1D array of 7*7*4 size\n",
    "        myresult = self.decimate(features) # pass that to our MLP classifier, and done!!!\n",
    "\n",
    "        return myresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dr Anderson's CNN with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets name oue neural network \"CNN_Anderson\"\n",
    "class CNN_Anderson_dropout(nn.Module):\n",
    "    \n",
    "    # this is our CNN_Anderson initilization function     \n",
    "    def __init__(self, size, num_classes):\n",
    "        # self is ... well ourself! (https://www.askpython.com/python/python-self-variable)\n",
    "        # other variables are ones we made up\n",
    "        #   size is the number of spectral bands in our image (e.g., MNIST is 1, RGB imagery is 3)\n",
    "        #   num_classes is the number of output neurons (e.g., num_classes = 10 for 10 classes in MNIST)\n",
    "\n",
    "        # lets call our super function (https://www.pythonforbeginners.com/super/working-python-super-function)\n",
    "        # we do this first,  call its init fx\n",
    "        super(CNN_Anderson, self).__init__()\n",
    "\n",
    "        # here is our \"feature extraction\" via convolutional layers \n",
    "        #   note: assume we got a single channel (grayscale) MNIST image of size 28x28x1\n",
    "        #         first layer\n",
    "        #             28x28x1 -> convolution (1 stride, 1 padd, 3x3 kernel, 2 kernels) -> 28x28x2\n",
    "        #         pooling\n",
    "        #             pool of 2x2 => 28x28 / 2 => 14x14 now (technically, 14x14x2 right!)\n",
    "        #         second layer\n",
    "        #             14x14x2 -> convolution (1 stride, 1 padd, 3x3 kernel, 4 kernels) -> 14x14x4\n",
    "        #         pooling\n",
    "        #             pool of 2x2 => 14x14 / 2 => 7x7 now (technically, 7x7x4 right!)\n",
    "        self.extract = nn.Sequential( # lets make a 2D convolution layer\n",
    "                                      nn.Conv2d( in_channels = size, out_channels = 2, \n",
    "                                                 kernel_size = 3, stride = 1, padding = 1), \n",
    "                                                     # in_channels = 1 for MNIST and 3 for RGB image\n",
    "                                                     # out_channels = 2 means 2 shared weights/features\n",
    "                                                     # kernel_size = 3 means a 3x3 size kernel\n",
    "                                                     # stride = 1 means move one pixel at a time in each dim\n",
    "                                                     # padding = adds one pixel of zeros to each side of each dim\n",
    "                                                     #           note, thats what keeps our spatial dims the same for a 3x3 kernel\n",
    "                                                     #           it also lets us process each location, even that border!!!\n",
    "                                      # its a NN, lets run a non-linearity on each of those results!\n",
    "                                      nn.ReLU(inplace = True),\n",
    "                                                     # could also use torch.nn.Sigmoid or etc.\n",
    "                                                     # inplace means don't have to return a result, do it on the data\n",
    "                                      # ----------------------------------------------------------- \n",
    "                                      # !!! hey, we just made a layer of convolution/nonlin !!!\n",
    "                                      # ----------------------------------------------------------- \n",
    "                                      # lets pool using a 2x2 region that is not overlapping\n",
    "                                      nn.MaxPool2d(2),                                                  \n",
    "                                      # lets do dropout with a small percentage/rate               \n",
    "                                      nn.Dropout(0.1),\n",
    "                                      # ----------------------------------------------------------- \n",
    "                                      # now, lets make another layer of convolution, pooling, and drop out\n",
    "                                      nn.Conv2d( in_channels = 2, out_channels = 4, \n",
    "                                                 kernel_size = 3, stride = 1, padding = 1),\n",
    "                                                 # in_channels here needs to match out_channels above\n",
    "                                                 # lets use 5 filters \n",
    "                                      nn.ReLU(inplace = True),\n",
    "                                      nn.MaxPool2d(2),\n",
    "                                      nn.Dropout(0.1), )\n",
    "\n",
    "        # ok, now we are going to make a simple MLP classifier on the end of our above features\n",
    "        self.decimate = nn.Sequential( nn.Linear(4*(7*7), 12),  \n",
    "                                            # take our 4 filters whose response fields are 7x7 to 12 neurons\n",
    "                                       nn.ReLU(inplace = True), # run a nonlinearity\n",
    "                                       nn.Dropout(0.2), # some drop out\n",
    "                                       nn.Linear(12, num_classes) ) # map the 32 down to our number of output classes\n",
    " \n",
    "    #----------------------------\n",
    "    # Model: Invoke Forward Pass\n",
    "    #----------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        features = self.extract(x) # easy, pass input (x) to our \"feature extraction\" above\n",
    "        features = features.view(features.size()[0], -1) # now, flatten 7x7x4 matrix to 1D array of 7*7*4 size\n",
    "        myresult = self.decimate(features) # pass that to our MLP classifier, and done!!!\n",
    "\n",
    "        return myresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dependent hyperparams\n",
    "input_size = 1\n",
    "num_classes = 10\n",
    "\n",
    "# model\n",
    "model = CNN_Anderson(input_size, num_classes)\n",
    "\n",
    "# some hyperparameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "costfx = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.3455\n",
      "Epoch [1/5], Step [200/938], Loss: 0.0975\n",
      "Epoch [1/5], Step [300/938], Loss: 0.0499\n",
      "Epoch [1/5], Step [400/938], Loss: 0.0767\n",
      "Epoch [1/5], Step [500/938], Loss: 0.1096\n",
      "Epoch [1/5], Step [600/938], Loss: 0.2611\n",
      "Epoch [1/5], Step [700/938], Loss: 0.0671\n",
      "Epoch [1/5], Step [800/938], Loss: 0.0230\n",
      "Epoch [1/5], Step [900/938], Loss: 0.1362\n",
      "Epoch [2/5], Step [100/938], Loss: 0.0437\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0179\n",
      "Epoch [2/5], Step [300/938], Loss: 0.0054\n",
      "Epoch [2/5], Step [400/938], Loss: 0.0121\n",
      "Epoch [2/5], Step [500/938], Loss: 0.0736\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     44\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     45\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[1;32mc:\\Users\\Zayan\\anaconda3\\envs\\ci_win\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Zayan\\anaconda3\\envs\\ci_win\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Zayan\\anaconda3\\envs\\ci_win\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Zayan\\anaconda3\\envs\\ci_win\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Zayan\\anaconda3\\envs\\ci_win\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\Zayan\\anaconda3\\envs\\ci_win\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # 'compose() allows stringing together multiple transformations.\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
