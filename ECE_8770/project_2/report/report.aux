\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nty/global//global/global}
\@writefile{toc}{\contentsline {section}{\numberline {1}Technical Description}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Recurrent Neural Networks}{1}{subsection.1.1}\protected@file@percent }
\abx@aux@cite{0}{zhang2023dive}
\abx@aux@segm{0}{0}{zhang2023dive}
\abx@aux@cite{0}{zhang2023dive}
\abx@aux@segm{0}{0}{zhang2023dive}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \blx@tocontentsinit {0}\cite {zhang2023dive}: On the left recurrent connections are depicted via cyclic edges. On the right, we unfold the RNN over time steps. Here, recurrent edges span adjacent time steps, while conventional connections are computed synchronously}}{2}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: rnns v1}{{1}{2}{\cite {zhang2023dive}: On the left recurrent connections are depicted via cyclic edges. On the right, we unfold the RNN over time steps. Here, recurrent edges span adjacent time steps, while conventional connections are computed synchronously}{figure.caption.2}{}}
\newlabel{eqn: h_t rnn}{{1}{2}{Recurrent Neural Networks}{equation.1.1}{}}
\newlabel{eqn: o_t rnn}{{2}{2}{Recurrent Neural Networks}{equation.1.2}{}}
\abx@aux@cite{0}{zhang2023dive}
\abx@aux@segm{0}{0}{zhang2023dive}
\abx@aux@cite{0}{zhang2023dive}
\abx@aux@segm{0}{0}{zhang2023dive}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Backpropagation through time (Backpropagation for RNNs)}{3}{subsubsection.1.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \blx@tocontentsinit {0}\cite {zhang2023dive}: Computational graph showing dependencies for an RNN model with three time steps. Boxes represent variables (not shaded) or parameters (shaded) and circles represent operators.}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig: rnns v2}{{2}{3}{\cite {zhang2023dive}: Computational graph showing dependencies for an RNN model with three time steps. Boxes represent variables (not shaded) or parameters (shaded) and circles represent operators}{figure.caption.3}{}}
\newlabel{eqn: total loss rnn}{{3}{3}{Backpropagation through time (Backpropagation for RNNs)}{equation.1.3}{}}
\newlabel{eqn: rnn lt wrt w_h}{{4}{3}{Backpropagation through time (Backpropagation for RNNs)}{equation.1.4}{}}
\newlabel{eqn: rnn h_t wrt w_h}{{5}{3}{Backpropagation through time (Backpropagation for RNNs)}{equation.1.5}{}}
\newlabel{eqn: rnn total loss wrt w_h}{{8}{3}{Backpropagation through time (Backpropagation for RNNs)}{equation.1.8}{}}
\abx@aux@cite{0}{zhang2023dive}
\abx@aux@segm{0}{0}{zhang2023dive}
\abx@aux@cite{0}{tallec2017unbiasing}
\abx@aux@segm{0}{0}{tallec2017unbiasing}
\abx@aux@cite{0}{zhang2023dive}
\abx@aux@segm{0}{0}{zhang2023dive}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparing strategies for computing gradients in RNNs. From top to bottom: randomized truncation, regular truncation, and full computation.}}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig: truncated_bptt}{{3}{4}{Comparing strategies for computing gradients in RNNs. From top to bottom: randomized truncation, regular truncation, and full computation}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Long Short Term Memory nets (LSTMs)}{4}{subsection.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces lstms}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig: lstms}{{4}{5}{lstms}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}RNN/LSTM configurations}{6}{subsection.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces From the left, the first picture is the one-to-one configuration, the second is the one-to-many configuration, third is version-1 of the many-to-many configuration and the fourth is version-2 of the many-to-many configuration.}}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig: RNN/LSTM configs}{{5}{6}{From the left, the first picture is the one-to-one configuration, the second is the one-to-many configuration, third is version-1 of the many-to-many configuration and the fourth is version-2 of the many-to-many configuration}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Experiments and Results}{6}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Training details}{7}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Results}{7}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces RNN(optimized by SGD) forecast results as sequence length is varied in a sequential setting}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig: SGD-RNN forecast results as sequence length is varied in a sequential setting}{{6}{8}{RNN(optimized by SGD) forecast results as sequence length is varied in a sequential setting}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces LSTM(optimized by SGD) forecast results as sequence length is varied in a sequential setting}}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig: SGD-LSTM forecast results as sequence length is varied in a sequential setting}{{7}{8}{LSTM(optimized by SGD) forecast results as sequence length is varied in a sequential setting}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces RNN(optimized by SGD) forecast results as sequence length is varied in a many to one setting}}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig: SGD-RNN forecast results as sequence length is varied in a many-to-one setting}{{8}{8}{RNN(optimized by SGD) forecast results as sequence length is varied in a many to one setting}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Conclusion}{8}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces LSTM(optimized by SGD) forecast results as sequence length is varied in a many to one setting}}{9}{figure.caption.10}\protected@file@percent }
\newlabel{fig: SGD-LSTM forecast results as sequence length is varied in a many-to-one setting}{{9}{9}{LSTM(optimized by SGD) forecast results as sequence length is varied in a many to one setting}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces RNN(optimized by Adam) forecast results as sequence length is varied in a sequential setting}}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig: Adam-RNN forecast results as sequence length is varied in a sequential setting}{{10}{9}{RNN(optimized by Adam) forecast results as sequence length is varied in a sequential setting}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces RNN(optimized by Adam) forecast results as sequence length is varied in a many to one setting}}{9}{figure.caption.12}\protected@file@percent }
\newlabel{fig: Adam-RNN forecast results as sequence length is varied in a many-to-one setting}{{11}{9}{RNN(optimized by Adam) forecast results as sequence length is varied in a many to one setting}{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces LSTM(optimized by Adam) forecast results as sequence length is varied in a sequential setting}}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig: Adam-LSTM forecast results as sequence length is varied in a sequential setting}{{12}{9}{LSTM(optimized by Adam) forecast results as sequence length is varied in a sequential setting}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces LSTM(optimized by Adam) forecast results as sequence length is varied in a many-to-one setting}}{10}{figure.caption.14}\protected@file@percent }
\newlabel{fig: Adam-LSTM forecast results as sequence length is varied in a many-to-one setting}{{13}{10}{LSTM(optimized by Adam) forecast results as sequence length is varied in a many-to-one setting}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Validation loss of all models after training}}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig: table of results}{{14}{10}{Validation loss of all models after training}{figure.caption.15}{}}
\abx@aux@cite{0}{multivariate_chain_rule}
\abx@aux@segm{0}{0}{multivariate_chain_rule}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proof of equation \ref {eqn: rnn h_t wrt w_h}}{11}{appendix.A}\protected@file@percent }
\newlabel{eq: l_t}{{19}{11}{Proof of equation \ref {eqn: rnn h_t wrt w_h}}{equation.A.19}{}}
\abx@aux@cite{0}{d2l_bptt}
\abx@aux@segm{0}{0}{d2l_bptt}
\newlabel{eq: h_t wrt wh}{{20}{12}{Proof of equation \ref {eqn: rnn h_t wrt w_h}}{equation.A.20}{}}
\newlabel{eq: h_t-1 wrt wh}{{21}{12}{Proof of equation \ref {eqn: rnn h_t wrt w_h}}{equation.A.21}{}}
\newlabel{eq: h_t-2 wrt wh}{{22}{12}{Proof of equation \ref {eqn: rnn h_t wrt w_h}}{equation.A.22}{}}
\abx@aux@read@bbl@mdfivesum{87F18E118053DECF6AE050898AF88FF6}
\abx@aux@defaultrefcontext{0}{d2l_bptt}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{multivariate_chain_rule}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{tallec2017unbiasing}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zhang2023dive}{nty/global//global/global}
\gdef \@abspage@last{14}
